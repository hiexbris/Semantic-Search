Backpropagation is a learning algorithm used for training neural networks, particularly deep neural networks with at least 2 hidden layers. It was applied to multi-layer neural networks by Geoffrey Hinton, David E. Rumelhart, and Ronald J. Williams during Hinton's postdoc at UC San Diego in the 1980s. This application demonstrated that such networks can learn useful internal representations of data.

In a feedforward neural network (which is the type used for backpropagation), the signal passes in only one direction. The learning process involves choosing weights that will get the right output for each input during training, with the goal of modeling complex relationships between inputs and outputs and finding patterns in data. Each node in the network applies a function, and once the weight crosses its specified threshold, the data is transmitted to the next layer.

The backpropagation algorithm works by computing the gradient of the loss function for each weight in the network. The gradient is calculated using chain rule of differentiation. During forward propagation, the input is passed through the network to produce an output. Then, during backward propagation, the algorithm computes the gradients of the weights based on the error at each layer and propagates these errors back through the network to adjust the weights. This process is repeated multiple times (iterations) until the network's performance on a validation set improves to a satisfactory level or stops improving significantly.

Notably, the concept of backpropagation was not invented by Hinton alone; it was proposed by Seppo Linnainmaa in 1970 and Paul Werbos proposed to use it to train neural networks in 1974. Furthermore, other contributions to neural network research by Geoffrey Hinton include distributed methods such as the support vector machine (SVM) and the displaced k-nearest neighbor in the 1990s, and the naive Bayes classifier, which is reportedly the "most widely used learner" at Google due to its scalability. Neural networks are also used as classifiers in various applications.